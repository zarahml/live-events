{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d86010-db5a-41e8-9f66-eb6c8c0b6863",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "52406132-9b3c-4b68-b190-8e87e4f2d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import config\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ebf54-40d8-4619-8c1b-4d8a116e1989",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# <font color = red><b> USER IMPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8466761a-c4fc-499c-a641-50cc6701c53d",
   "metadata": {},
   "source": [
    "<b>REQUIRED: </b>`states`, `start_date`, `end_date`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "08f261c4-5745-462e-848e-2ddeff951699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of states: use two character abbreviations.\n",
    "states = ['AL', 'AK', 'AZ', 'AR', \n",
    "         # 'CA', 'CO', 'CT', 'DE',\n",
    "         # 'DC', 'FL', 'GA', 'HI',\n",
    "         # 'ID', 'IL', 'IN', 'IA',\n",
    "         # 'KS', 'KY', 'LA', 'ME',\n",
    "         # 'MD', 'MA', 'MI', 'MN',\n",
    "         # 'MS', 'MO', 'MT', 'NE', \n",
    "         # 'NV', 'NH', 'NJ', 'NM',\n",
    "         # 'NY', 'NC', 'ND', 'OH',\n",
    "         # 'OK', 'OR', 'PA', 'RI',\n",
    "         # 'SC', 'SD', 'TN', 'TX',\n",
    "         # 'UT', 'VT', 'VA', 'WA',\n",
    "         # 'WV', 'WI', 'WY'\n",
    "         ]\n",
    "\n",
    "#date range: use formatting appropriate for file saving as these values are used in the file names.\n",
    "start_date = '12-31-2022'\n",
    "end_date = '12-31-2022'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e2e52-f43f-4856-a980-63900a326a89",
   "metadata": {},
   "source": [
    "<b>OPTIONAL:</b> `save_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "6bea2cad-a9e9-4c54-b082-4262165d75be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify save path for event files csv files\n",
    "save_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782ada4-5b75-4429-b718-2d139a8e7e94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Get Events from Ticketmaster Discovery API\n",
    "---\n",
    "<font color = red> <b>USER INPUTS:</b></font> `states list`, `start_date`, `end_date`, and `[save_path]`<br>\n",
    "<b>OUTPUT: for each state: `event-json_[state]_[start_date]_[end_date].csv`</b>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a795013d-c18c-4502-aa98-8b17feca42c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## –– Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e54bdc-33f4-4494-8e3b-5468b1c17b06",
   "metadata": {},
   "source": [
    "Event get request for specific `state`, `date`, `page size`, and `[page number]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "16370339-fe3a-44c3-b206-870602763200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event(state, date, size, KEY, page = None):\n",
    "    \n",
    "    #page one of events will not have a specified page number\n",
    "    if page == None: #use this if request is for the first page\n",
    "        \n",
    "        return requests.get(f'https://app.ticketmaster.com/discovery/v2/events.json?stateCode={state}&startDateTime={date}T00:00:00Z&endDateTime={date}T23:59:59Z&size={size}&apikey={KEY}').json()\n",
    "    \n",
    "    else: #use this if request is for pages 2+\n",
    "        \n",
    "        return requests.get(f'https://app.ticketmaster.com/discovery/v2/events.json?stateCode={state}&startDateTime={date}T00:00:00Z&endDateTime={date}T23:59:59Z&size={size}&page={page}&apikey={KEY}').json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab68095-7a1a-48dd-aae3-9029780ad09d",
   "metadata": {},
   "source": [
    "Generate a list of strings containing a range of dates in 'YYYY-MM-DD' format given `start_date` and `end_date` strings of any format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "cf467832-7971-4999-b3e6-4b76391b9fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_date_list(start_date, end_date):\n",
    "    \n",
    "    timestamps = pd.date_range(start=start_date, end=end_date)\n",
    "   \n",
    "    date_list = []\n",
    "    \n",
    "    for i in timestamps:\n",
    "        \n",
    "        date_list.append(str(i)[:10])\n",
    "        \n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17a186-1062-4a2f-b244-7da7db0cb99a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Returns 3 lists containing a list of events, a list of days that had zero events, and a list of days with over 1000 events + the number of events for that day.</br>\n",
    "Must specify `state`, `start_date`, and `end_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "2d0f2f44-1a7c-4e14-a8f8-4465a85b04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_in_date_list(state, start_date, end_date):\n",
    "    \n",
    "    #generate date list given start date and end date\n",
    "    date_list = generate_date_list(start_date, end_date)\n",
    "   \n",
    "    #initiate list objects to return\n",
    "    event_list = []\n",
    "    \n",
    "    dates_with_over_1000_events = []\n",
    "    \n",
    "    dates_with_0_events = []\n",
    "    \n",
    "    #cycle through each day in the date list\n",
    "    for date in date_list:\n",
    "        \n",
    "        #initiate variables specific to each day\n",
    "        size = 200\n",
    "        \n",
    "        totalElements = 1\n",
    "        \n",
    "        totalPages = 1\n",
    "        \n",
    "        #try to get first page and throw exception for days with zero events\n",
    "        try:\n",
    "            current_get = get_event(state, date, size, config.KEY)\n",
    "            \n",
    "            #update total elements and number of pages\n",
    "            totalElements = current_get['page']['totalElements']\n",
    "            \n",
    "            totalPages = current_get['page']['totalPages']\n",
    "            \n",
    "            #output for testing: print(f'{date}: totalElements, {totalElements}; totalPages, {totalPages}; size, {size}')\n",
    "            \n",
    "            #if date has more than 1000 events, add date to list for alt processing\n",
    "            if totalElements > 1000:\n",
    "                \n",
    "                #output for testing: print(f'{date} has over 1000')\n",
    "                dates_with_over_1000_events.append([date,totalPages])\n",
    "                \n",
    "                break\n",
    "            \n",
    "            #output for testing: print(f'page 1')\n",
    "            \n",
    "            #add first page to event list\n",
    "            event_list.extend(current_get['_embedded']['events'])\n",
    "            \n",
    "            #cycle through the rest of the pages of events for that day\n",
    "            for i in range(2,totalPages+1):\n",
    "                \n",
    "                #check if loop is on last page\n",
    "                if i == totalPages:\n",
    "                    \n",
    "                    #determine correct size for the last page (if size is not exact api will return no events)\n",
    "                    size = totalElements % size\n",
    "                \n",
    "                #output for testing: print(f'page {i}')\n",
    "                \n",
    "                #get page of events\n",
    "                current_get = get_event(state, date, size, config.KEY, i)\n",
    "                \n",
    "                #add events to event lists as individual events\n",
    "                event_list.extend(current_get['_embedded']['events'])\n",
    "        \n",
    "        except:\n",
    "            #add day to list of days which had no events\n",
    "            dates_with_0_events.append(date)\n",
    "    \n",
    "    return event_list, dates_with_over_1000_events, dates_with_0_events\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a3387-ff05-4eb0-94a9-3ee13d2c9b50",
   "metadata": {},
   "source": [
    "Given a list of `states`, `start_date`, `end_date`, and `save_path`: <br> • Save a csv containing all events for each state in the list for the given date range. <br>• Print out the dates which had no events, and the days which had more than 1000 events.<i> If one exists, a function will need to be written to split the day up into different time chunks to reduce the number of events in the API call to less than 1000. So far, I have not encountered a need to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "7f19bcd6-cfb6-40a1-afca-e1266d08bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_for_all_states(states, start_date, end_date, save_path = ''):\n",
    "    \n",
    "    print(f'Date Range: {start_date} to {end_date}')\n",
    "    for state in states:\n",
    "        #get events and create a list of dates that had over 1000 or 0 events\n",
    "        events, large_dates, zero_dates = get_events_in_date_list(state, start_date, end_date)\n",
    "        #generate report for each state based on lengths of lists\n",
    "        total_events = len(events)\n",
    "        total_large_dates = len(large_dates)\n",
    "        total_zero_dates = len(zero_dates)\n",
    "        #report output:\n",
    "        print('__________________________________________')\n",
    "        print(state)\n",
    "        if total_events > 0:\n",
    "            print(f'    total events: {total_events}')\n",
    "        if total_large_dates > 0:\n",
    "            print(f'    1000+ events: {large_dates}')\n",
    "        if total_zero_dates > 0: \n",
    "            print(f'    zero events: {zero_dates}')\n",
    "        #save json as data frame \n",
    "        events_df = pd.DataFrame(events)\n",
    "        events_df.to_csv(f'{save_path}event-json_{state}_{start_date}_{end_date}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d21007f-fee6-42a8-b09a-a3a2ccc52b2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## –– Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "79065ebd-8f48-4303-8cdd-0aa1713de131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Range: 12-31-2022 to 12-31-2022\n",
      "__________________________________________\n",
      "AL\n",
      "    total events: 5\n",
      "__________________________________________\n",
      "AK\n",
      "    zero events: ['2022-12-31']\n",
      "__________________________________________\n",
      "AZ\n",
      "    total events: 31\n",
      "__________________________________________\n",
      "AR\n",
      "    total events: 1\n"
     ]
    }
   ],
   "source": [
    "get_events_for_all_states(states, start_date, end_date, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42dcc3-448b-4c33-a11a-5a2936e9d8d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2. Extract & Flatten Event Information\n",
    "---\n",
    "<b>INPUT:</b> for each state: `event-json_[state]_[start_date]_[end_date].csv`<br>\n",
    "<b>OUTPUT:</b> for each state: `event-expanded_[state]_[start_date]_[end_date].csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df63d9-2b70-486e-bf3c-79ef1ce51056",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## –– Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b9c93-ab21-437b-8177-d108ea8b25cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create Record\n",
    "For each record, return variables containing flattened features. \n",
    "Some information is contained in a string. ast.literal_eval is used to remove outer quotations so the inner dictionaries can be accessed. Some records are missing information. This function checks to see if the information is there, if not, the variable is assigned a None value. For example, if there is no promoter listed, promoter_name will be assigned a None value. \n",
    "Some variables are returned which will determine if there are multiple attractions or dmas which will need to be addressed in a following funciton. \n",
    "For example, sports games will list two attractions, one for each of the teams playing eachother. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "70cf8c8f-dc95-4dea-9625-f2be3c2d6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record(event, attractions_index = 0, classifications_index = 0, venues_index = 0, markets_index = 0, dmas_index = 0):\n",
    "    # event id & name\n",
    "    event_id = event['id']\n",
    "    event_name = event['name']\n",
    "    #event date\n",
    "    dates = ast.literal_eval(event['dates'])\n",
    "    localDate = dates['start']['localDate']\n",
    "    # does the event span multiple days\n",
    "    spanMultipleDays = dates['spanMultipleDays']\n",
    "    #json contains string which needs to be evaluated as code multiple times, this allows the eval to happen only once. \n",
    "    embedded = ast.literal_eval(event['_embedded'])\n",
    "    #event type & subtype\n",
    "    try: \n",
    "        event_classifications: ast.literal_eval(event['classifications'])\n",
    "        event_type = event_classifications[0]['type']['name']\n",
    "        event_subType = event_classifications[0]['subType']['name']\n",
    "    except: \n",
    "        event_type = None\n",
    "        event_subType = None\n",
    "    #promoter id, name, description\n",
    "    try:\n",
    "        promoter = ast.literal_eval(event['promoter'])\n",
    "        promoter_id = promoter['id']\n",
    "        promoter_name = promoter['name']\n",
    "        promoter_description = promoter['description']\n",
    "    except: \n",
    "        promoter_id = None\n",
    "        promoter_name = None\n",
    "        promoter_description = None\n",
    "    #price min & max\n",
    "    try:\n",
    "        price = ast.literal_eval(event['priceRanges'])[0]\n",
    "        price_min = price['min']\n",
    "        price_max = price['max']\n",
    "    except: \n",
    "        price_min = None\n",
    "        price_max = None\n",
    "    #age restrictions \n",
    "    try: \n",
    "        age_restrictions = ast.literal_eval(event['ageRestrictions'])\n",
    "        legalAgeEnforced = age_restrictions['legalAgeEnforced']\n",
    "    except: \n",
    "        legalAgeEnforced = None\n",
    "    #attraction segment, genre, & subgenre\n",
    "    try: segment = embedded['attractions'][0]['classifications'][0]['segment']['name']\n",
    "    except: segment = None\n",
    "    try: genre = embedded['attractions'][0]['classifications'][0]['genre']['name']\n",
    "    except: genre = None\n",
    "    try: subGenre = embedded['attractions'][0]['classifications'][0]['subGenre']['name']\n",
    "    except: subGenre = None\n",
    "    #venue id & name\n",
    "    try: venue_id = embedded['venues'][0]['id']\n",
    "    except: venue_id = None\n",
    "    try: venue_name = embedded['venues'][0]['name']\n",
    "    except: venue_name = None\n",
    "    #venue latitude & longitude\n",
    "    try: \n",
    "        latitude = float(embedded['venues'][0]['location']['latitude'])\n",
    "        longitude = float(embedded['venues'][0]['location']['longitude'])\n",
    "    except: \n",
    "        latitude = None\n",
    "        longitude = None\n",
    "    #venue address\n",
    "    try: postal_code = embedded['venues'][0]['postalCode']\n",
    "    except: postal_code = None\n",
    "    try: state = embedded['venues'][0]['state']['name']\n",
    "    except: state = None\n",
    "    try: city = embedded['venues'][0]['city']['name']\n",
    "    except: city = None\n",
    "    try: address = embedded['venues'][0]['address']['line1']\n",
    "    except: address = None\n",
    "    #venue markets & dmas\n",
    "    try: market_count = len(embedded['venues'][0]['markets'])\n",
    "    except: market_count = 0\n",
    "    try: market = embedded['venues'][0]['markets'][0]['name']\n",
    "    except: market = None\n",
    "    try: dma_count = len(embedded['venues'][0]['dmas'])\n",
    "    except: dma_count = 0\n",
    "    try: dma = embedded['venues'][0]['dmas'][0]['id']\n",
    "    except: dma = None\n",
    "    #attraction info\n",
    "    try:attraction_count = len(embedded['attractions'])\n",
    "    except: attraction_count = 0\n",
    "    try: attraction_id = embedded['attractions'][0]['id']\n",
    "    except: attraction_id = None\n",
    "    try: attraction_name = embedded['attractions'][0]['name']\n",
    "    except: attraction_name = None\n",
    "    try: attraction_img = embedded['attractions'][0]['images'][0]['url']\n",
    "    except: attraction_img = None\n",
    "    #return all relevant variables\n",
    "    return event_id, event_name, localDate, spanMultipleDays, segment, genre, subGenre, event_type, event_subType, promoter_id, promoter_name, promoter_description, price_min, price_max, legalAgeEnforced, venue_id, venue_name, address, city, state, postal_code, latitude, longitude, market_count, market, dma_count, dma, attraction_count, attraction_id, attraction_name, attraction_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ff3fe-ba3c-40c0-9c4d-81df2ef7b3e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Flatten Records\n",
    "Events only list first attraction. If there is an event with 2 teams playing for example, only one will be listed. A second record will be added in `add_multiple_attractions()` for the second team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "dc251540-bd1d-42ed-8b69-6a5a6efc55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_event_json(state, start_date, end_date, save_path=''):\n",
    "    #read in event_json csv\n",
    "    event_json = pd.read_csv(f'{save_path}event-json_{state}_{start_date}_{end_date}.csv')\n",
    "    #define new dataframe to hold flattened data\n",
    "    event_flattened = pd.DataFrame(columns = [\n",
    "                                 'event_id', \n",
    "                                 'event_name',\n",
    "                                 'localDate',\n",
    "                                 'spanMultipleDays',\n",
    "                                 'segment',\n",
    "                                 'genre',\n",
    "                                 'subGenre',\n",
    "                                 'event_type',\n",
    "                                 'event_subType',\n",
    "                                 'promoter_id',\n",
    "                                 'promoter_name',\n",
    "                                 'promoter_description',\n",
    "                                 'price_min',\n",
    "                                 'price_max',\n",
    "                                 'legalAgeEnforced',\n",
    "                                 'venue_id',\n",
    "                                 'venue_name',\n",
    "                                 'address',\n",
    "                                 'city',\n",
    "                                 'state',\n",
    "                                 'postal_code',\n",
    "                                 'latitude', \n",
    "                                 'longitude', \n",
    "                                 'market', \n",
    "                                 'dma', \n",
    "                                 'attraction_id',\n",
    "                                 'attraction_name', #\n",
    "                                 'attraction_img' #\n",
    "                                  ],\n",
    "                        #determine how many records will be in the dataframe\n",
    "                        #index = range(0,2))\n",
    "                        index = range(len(event_json)))\n",
    "    #initiate dictionaries to track which events have multiples and will need further transformation\n",
    "    multiple_attractions = {}\n",
    "    multiple_markets = {}\n",
    "    multiple_dmas = {}\n",
    "    #shorter range for troubleshooting:\n",
    "    #for i in range(2):\n",
    "    for i in range(len(event_json)):\n",
    "        #for each event in event_json, extract data and add to flattened dataframe\n",
    "        try: \n",
    "            event_id, event_name, localDate, spanMultipleDays, segment, genre, subGenre, event_type, event_subType, promoter_id, promoter_name, promoter_description, price_min, price_max, legalAgeEnforced, venue_id, venue_name, address, city, state, postal_code, latitude, longitude, market_count, market, dma_count, dma, attraction_count, attraction_id, attraction_name, attraction_img = create_record(event_json.iloc[i])\n",
    "            event_flattened.iloc[i] = [\n",
    "                    event_id,\n",
    "                    event_name,\n",
    "                    localDate,\n",
    "                    spanMultipleDays,\n",
    "                    segment,\n",
    "                    genre,\n",
    "                    subGenre,\n",
    "                    event_type,\n",
    "                    event_subType,\n",
    "                    promoter_id,\n",
    "                    promoter_name,\n",
    "                    promoter_description,\n",
    "                    price_min,\n",
    "                    price_max,\n",
    "                    legalAgeEnforced,\n",
    "                    venue_id,\n",
    "                    venue_name,\n",
    "                    address,\n",
    "                    city,\n",
    "                    state,\n",
    "                    postal_code,\n",
    "                    latitude,\n",
    "                    longitude,\n",
    "                    market,\n",
    "                    dma,\n",
    "                    attraction_id, \n",
    "                    attraction_name, \n",
    "                    attraction_img\n",
    "                   ]\n",
    "            #if there are multiple attractions, markets, or dmas, add the index of that event to the dictionary along with the total number of multiples\n",
    "            if attraction_count > 1:\n",
    "                multiple_attractions[i] = attraction_count\n",
    "            if market_count > 1:\n",
    "                multiple_markets[i] = market_count\n",
    "            if dma_count > 1:\n",
    "                multiple_dmas[i] = dma_count\n",
    "        except:\n",
    "            print(f'could not add index:{i}')\n",
    "    #report output\n",
    "    print(f'    records: {len(event_flattened)}')\n",
    "    print(f'    filled records: {i+1}')\n",
    "    print(f'    multiple attractions: {len(multiple_attractions)}')\n",
    "    print(f'    attractions to add: {sum(multiple_attractions.values())-len(multiple_attractions)}')\n",
    "    print(f'    multiple markets: {len(multiple_markets)}')\n",
    "    print(f'    multiple dmas: {len(multiple_dmas)}')\n",
    "    return event_json, event_flattened, multiple_attractions, multiple_markets, multiple_dmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617f8e8-6661-4af6-92e1-479f7640ac6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add Records With Multiple Attractions\n",
    "If unique events are desired, group by unique events will be needed in the future. There will be more records than there are events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "7e791729-2924-4098-b202-0115af9d36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_multiple_attractions(multiple_attractions, event_flattened, event_json):\n",
    "    #initiate event_expanded dataframe that will be saved as initial flattened and expanded csv used in the data cleaning stpes. \n",
    "    event_expanded = pd.DataFrame(event_flattened)\n",
    "    #step through the events listed in the multiple_attractions dictionary and add a row for each\n",
    "    for i in multiple_attractions:\n",
    "        for j in range(1,multiple_attractions[i]):\n",
    "            #attraction id, name & img url\n",
    "            try: attraction_id = attraction['id']\n",
    "            except: attraction_id = None\n",
    "            try: attraction_name = attraction['name']\n",
    "            except: attraction_name = None\n",
    "            try: attraction_img = attraction['images'][0]['url']\n",
    "            except: attraction_img = None\n",
    "            #attraction segment, genre, subgenre: if the seconds+ attractions do not list a segment, genre or subgenre, use the data from the first attraction\n",
    "            attraction = ast.literal_eval(event_json.loc[i]['_embedded'])['attractions'][j]\n",
    "            first_attraction = ast.literal_eval(event_json.loc[i]['_embedded'])['attractions'][0]\n",
    "            try: segment = attraction['classifications'][0]['segment']['name']\n",
    "            except:\n",
    "                try: segment = first_attraction['classifications'][0]['segment']['name']\n",
    "                except: segment = None\n",
    "            try: genre = attraction['classifications'][0]['genre']['name']\n",
    "            except:\n",
    "                try: genre = first_attracton['classifications'][0]['genre']['name']\n",
    "                except: genre = None\n",
    "            try: subGenre = ['classifications'][0]['subGenre']['name']\n",
    "            except: \n",
    "                try: subGenre = first_attraction['classifications'][0]['subGenre']['name']\n",
    "                except: subGenre = None\n",
    "            #add new record to the end of the dataframe with new info\n",
    "            event_expanded.loc[len(event_expanded.index)] = [\n",
    "                        event_expanded.iloc[i]['event_id'],\n",
    "                        event_expanded.iloc[i]['event_name'],\n",
    "                        event_expanded.iloc[i]['localDate'],\n",
    "                        event_expanded.iloc[i]['spanMultipleDays'],\n",
    "                        segment,\n",
    "                        genre,\n",
    "                        subGenre,\n",
    "                        event_expanded.iloc[i]['event_type'],\n",
    "                        event_expanded.iloc[i]['event_subType'],\n",
    "                        event_expanded.iloc[i]['promoter_id'],\n",
    "                        event_expanded.iloc[i]['promoter_name'],\n",
    "                        event_expanded.iloc[i]['promoter_description'],\n",
    "                        event_expanded.iloc[i]['price_min'],\n",
    "                        event_expanded.iloc[i]['price_max'],\n",
    "                        event_expanded.iloc[i]['legalAgeEnforced'],\n",
    "                        event_expanded.iloc[i]['venue_id'],\n",
    "                        event_expanded.iloc[i]['venue_name'],\n",
    "                        event_expanded.iloc[i]['address'],\n",
    "                        event_expanded.iloc[i]['city'],\n",
    "                        event_expanded.iloc[i]['state'],\n",
    "                        event_expanded.iloc[i]['postal_code'],\n",
    "                        event_expanded.iloc[i]['latitude'],\n",
    "                        event_expanded.iloc[i]['longitude'],\n",
    "                        event_expanded.iloc[i]['market'],\n",
    "                        event_expanded.iloc[i]['dma'],\n",
    "                        attraction_id, \n",
    "                        attraction_name, \n",
    "                        attraction_img\n",
    "                       ]\n",
    "    #report output:\n",
    "    print('    ––––––––––––––––––––––––')\n",
    "    print(f'    attractions added: {len(event_expanded)-len(event_flattened)}')\n",
    "    print(f'    end records: {len(event_expanded)}')\n",
    "    return event_expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb29b84-a4d2-4ca2-b62e-85db5f85741a",
   "metadata": {},
   "source": [
    "### Expand Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "a439d427-2361-4aff-ab40-52c1643b4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of states that are not able to be expanded\n",
    "not_expanded = []\n",
    "\n",
    "def expand_event(state, start_date, end_date, save_path = ''):\n",
    "    #report output:\n",
    "    print('––––––––––––––––––––––––––––––––––––')\n",
    "    print(f'{state}')\n",
    "    #initiate variables, create expanded version, save to csv.\n",
    "    try:\n",
    "        event_json, event_flattened, multiple_attractions, multiple_markets, multiple_dmas = flatten_event_json(state, start_date, end_date, save_path)\n",
    "        event_expanded = add_multiple_attractions(multiple_attractions, event_flattened, event_json)\n",
    "        event_expanded.to_csv(f'{save_path}event_expanded_{state}_{start_date}_{end_date}.csv')\n",
    "    except:\n",
    "        #add state to list of states that could not be expanded\n",
    "        not_expanded.append(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa5815a-5dab-40bf-808a-30645032b9a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## –– Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "b59d9a2b-e267-4b8f-abdf-50591fceb7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT for ['AL', 'AK', 'AZ', 'AR'] \n",
      "DATERANGE: 12-31-2022 to 12-31-2022\n",
      "––––––––––––––––––––––––––––––––––––\n",
      "AL\n",
      "    records: 5\n",
      "    filled records: 5\n",
      "    multiple attractions: 3\n",
      "    attractions to add: 3\n",
      "    multiple markets: 0\n",
      "    multiple dmas: 5\n",
      "    ––––––––––––––––––––––––\n",
      "    attractions added: 3\n",
      "    end records: 8\n",
      "––––––––––––––––––––––––––––––––––––\n",
      "AK\n",
      "    records: 0\n",
      "––––––––––––––––––––––––––––––––––––\n",
      "AZ\n",
      "    records: 31\n",
      "    filled records: 31\n",
      "    multiple attractions: 2\n",
      "    attractions to add: 2\n",
      "    multiple markets: 0\n",
      "    multiple dmas: 25\n",
      "    ––––––––––––––––––––––––\n",
      "    attractions added: 2\n",
      "    end records: 33\n",
      "––––––––––––––––––––––––––––––––––––\n",
      "AR\n",
      "    records: 1\n",
      "    filled records: 1\n",
      "    multiple attractions: 0\n",
      "    attractions to add: 0\n",
      "    multiple markets: 0\n",
      "    multiple dmas: 1\n",
      "    ––––––––––––––––––––––––\n",
      "    attractions added: 0\n",
      "    end records: 1\n",
      "––––––––––––––––––––––––––––––––––––\n",
      "Unsuccessful: ['AK']\n"
     ]
    }
   ],
   "source": [
    "#report_output\n",
    "print(f'REPORT for {states} \\nDATERANGE: {start_date} to {end_date}')\n",
    "#step through event_jsons and expand and save each\n",
    "for state in states:\n",
    "    expand_event(state, start_date, end_date, save_path)\n",
    "#report output:   \n",
    "print(f'––––––––––––––––––––––––––––––––––––\\nUnsuccessful: {not_saved}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab07ca-5288-4880-98af-49ed87f5659a",
   "metadata": {},
   "source": [
    "# To Do: Combine expanded events into one csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
